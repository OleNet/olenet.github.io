---
layout: post
title:  LSTM
toc: true 
excerpt: 
date:   2018-08-20
---


LSTM=long-short-term-memory

LSTM的输入有

- 上一个cell的信息$C_{t-1}$
- 上一个cell的输出$h_{t-1}$
- 本轮的输入$x_t$

输出是

- 当前cell的信息$C_{t}$

- 当前cell的输出$h_{t}​$

  

LSTM的精髓在遗忘过去的信息$C_{t-1}$即：

$C_{t}=tanh(f_tC_{t-1}+i_t\tilde{C})$

其中我将$f_t$叫做遗忘因子，$i_t$叫做记忆因子。

因为$\tilde{C}=W[x_t, h_{t-1}]+b$,即$\tilde{C}$仅用到了历史信息表达$h_{t-1}$，所以我认为$\tilde{C}$是cell的一个不完整信息的表达。



而遗忘因子$f_t$和记忆因子$i_t$也是通过历史信息建模得到:

$f_t=\sigma(W_f[x_t, h_{t-1}]+b_f)$

$i_t=\sigma(W_i[x_t, h_{t-1}]+b_i)$



有了当前cell的表达$C_t$，就可以计算当前cell的输出了:

$o_t=W_o[x_t, h_{t-1}]+b_o$

$h_t =o_ttanh(C_t)$