---
layout: post
title:  Bandit 算法
toc: true 
excerpt: 
date:   2018-07-26
---

bandit 算法是解决一排老虎机选择玩哪个老虎机的问题的。

有一排老虎机，获胜的概率不一样，但是我们不知道这个概率，我们要选择一个最靠谱的方法，能够用最低的成本挑出这个牛逼的老虎机。

最直白的方式，是每一个老虎机都实验1000次，然后算出来每一个老虎机回报的置信区间，可是这样做成本太高了。

科学家提出了很多算法，想什么Thompson算法、UCB算法、LinUCB算法，RL里面常用的Epsilon-Greedy算法。

稍微提一下UCB算法和LinUCB算法。

UCB很简单，一个简单的思想，用置信区间上限来选择最优老虎机。

$$ \bar{x}+\sqrt{\frac{2ln{t}}{T_{j,t}}}$$

$\bar{x}$是回报的均值，加上后面的项就是置信区间上限。

当然这样做的话，对于老虎机没问题。但是如果应用在推荐系统里面，把商品作为老虎机就有问题了，因为这种方式丢失了一些特征信息，对于一个新的物品，没有对用户和商品的信息进行建模，能对这个物品的预测，只能从0开始。



LinUCB就是在这个问题的基础上，引入了Context信息。

既然需要Context，那就需要特征，假设我们提取除了一些用户和商品的信息特征，$x \in \mathit{R}^d$

我们希望学习到一组具有泛化能力的参数$\Theta \in R^{d · c}$时的$x\Theta \in R^c$接近真实评分$y$



这样我就可以迭代数次，每次迭代，按照UCB公式选择最优的老虎机，然后再更新$\Theta$，迭代至指定的次数停止更新。

