---
layout: post
title:  Memory-networks
toc: true 
excerpt: 
date:   2018-07-30
---
# MEMORY NETWORKS

1. 这篇文章什么领域的

   QA

2. 这篇文章解决什么问题的

   QA问题中的类RNN方法中的记忆单元太小了，记不住东西。索性就将记忆单元外化，解决长期记忆的问题。单独提取一个记忆模块，就像内存的RAM。这个记忆单元可以接受更新，也可以根据输入得到最相近的记忆信息，根据这条信息再继续发现第二相近的记忆信息，以此类推。最后根据这些记忆信息经过decoder得到答案。

3. 这篇文章的解决方法表面是什么

   创新的框架，有输入单元$I$, 输出单元O, 泛化单元$G$, 回复单元 $R$.输入的数据形式不限，可以通过$I$转化成向量，通过$G$ 得到记忆向量(可以是多个向量)，通过$O$整合$G$得到$decoder$的输入向量, 进而通过$R$得到输出。

4. 这篇文章的解决方法背后的物理意义是什么

   记忆单元外化，强化记忆组件

5. 这篇文章的亮点是什么

   创新的框架，对多种应对状况的比较完善的实用方法介绍。

6. 最终效果怎么样

   比传统方法要好, 数据集是Fader等人的QA数据集。

   ![image-20180730113709086](/Users/liujiaxiang/Document/olenet.github.io/_posts/static/pics/memnetwork-result.png)

7. 对当前的工作有什么借鉴意义

   文章中有一个章节讲的是unseen words的处理，方法比较通用，即使用unseen word周围的词向量对该word进行表示。为了强化这点，在训练过程中，还以一定的概率对词表中的词汇使用该技巧来训练模型对这一特性的表达。

   另外文章也将了大规模数据中，如果解决速度问题：对memory进行聚类，在寻找memory的时候，先寻找对应的簇。

8. 这篇文章发论文的套路是什么

   创新的解决问题的框架，比较完善的使用说明。

